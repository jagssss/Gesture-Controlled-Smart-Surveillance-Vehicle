Code for Face Recognition Code for making dataset:

import cv2 import os
# set video height
faceCascade = cv2.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml') # For each person, enter one numeric face id
face_id = input('\n enter user id end press <return> ==> ')
print("\n [INFO] Initializing face capture. Look the camera and wait ...") cap = cv2.VideoCapture(0)
# Initialize individual sampling face count
count = 0
while True:
ret, img = cap.read()
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) faces = faceCascade.detectMultiScale(img) print(faces)
for (x,y,w,h) in faces:
print("Jagrit") cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) count+=1
cv2.imwrite("Jagrit2/User." + str(face_id) + '.' +
str(count) + ".jpg", img[y:y+h,x:x+w]) roi_gray = gray[y:y+h, x:x+w]
roi_color = img[y:y+h, x:x+w]
print("Jagrit")
k = cv2.waitKey(30) & 0xff
if k == 27: # press 'ESC' to quit break
elif count >=10: break
cap.release() cv2.destroyAllWindows()

Code for training Model:

import cv2
import numpy as np
from PIL import Image
import os
# Path for face image database
path = 'trainit'
recognizer = cv2.face.LBPHFaceRecognizer_create()
detector = cv2.CascadeClassifier("Haarcascades/haarcascade_frontalface_default.xml"); # function to get the images and label data
def getImagesAndLabels(path):
imagePaths = [os.path.join(path,f) for f in os.listdir(path)] faceSamples=[]
ids = []
for imagePath in imagePaths:
PIL_img = Image.open(imagePath).convert('L') # grayscale img_numpy = np.array(PIL_img,'uint8')
id = int(os.path.split(imagePath)[-1].split(".")[1])
faces = detector.detectMultiScale(img_numpy)
for (x,y,w,h) in faces: faceSamples.append(img_numpy[y:y+h,x:x+w]) ids.append(id)
return faceSamples,ids
print ("\n [INFO] Training faces. It will take a few seconds. Wait ...")
faces,ids = getImagesAndLabels(path)
recognizer.train(faces, np.array(ids))
# Save the model into trainer/trainer.yml
recognizer.write('trainer/trainer.yml')
# Print the numer of faces trained and end program
print("\n [INFO] {0} faces trained. Exiting Program".format(len(np.unique(ids))))

Code for Recognising face:

import cv2 import numpy as
np import os
import whatsapp
import io
import picamera
import logging
import socketserver
from threading import Condition from http import server
PAGE="""\
<html>
<head>
<title>Raspberry Pi - Surveillance Camera</title> </head>
<body>
<center><h1>Raspberry Pi - Surveillance Camera</h1></center>
<center><img src="stream.mjpg" width="640" height="480"></center>
</body>
</html> """
class StreamingOutput(object): def init (self):
self.frame = None self.buffer = io.BytesIO() self.condition = Condition()
def write(self, buf):
if buf.startswith(b'\xff\xd8'):
# New frame, copy the existing buffer's content and notify all # clients it's available
self.buffer.truncate()
with self.condition:
self.frame = self.buffer.getvalue()
self.condition.notify_all() self.buffer.seek(0)
return self.buffer.write(buf)
class StreamingHandler(server.BaseHTTPRequestHandler): def do_GET(self):
if self.path == '/': self.send_response(301)
 self.send_header('Location', '/index.html')
self.end_headers()
elif self.path == '/index.html':
content = PAGE.encode('utf-8') self.send_response(200) self.send_header('Content-Type', 'text/html') self.send_header('Content-Length', len(content)) self.end_headers()
self.wfile.write(content)
elif self.path == '/stream.mjpg':
self.send_response(200)
self.send_header('Age', 0)
self.send_header('Cache-Control', 'no-cache, private') self.send_header('Pragma', 'no-cache') self.send_header('Content-Type', 'multipart/x-mixed-replace;
boundary=FRAME')
self.end_headers() try:
while True:
with output.condition: output.condition.wait() frame = output.frame
self.wfile.write(b'--FRAME\r\n') self.send_header('Content-Type', 'image/jpeg') self.send_header('Content-Length', len(frame)) self.end_headers()
self.wfile.write(frame)
self.wfile.write(b'\r\n') except Exception as e:
logging.warning(
'Removed streaming client %s: %s', self.client_address, str(e))
else: self.send_error(404) self.end_headers()
output = StreamingOutput()
class StreamingServer(socketserver.ThreadingMixIn, server.HTTPServer):
allow_reuse_address = True
daemon_threads = True def live():
with picamera.PiCamera(resolution='640x480', framerate=24) as camera:
#Uncomment the next line to change your Pi's Camera rotation (in degrees) camera.rotation = 180
camera.start_recording(output, format='mjpeg')
try:
address = ('', 8000)
server = StreamingServer(address, StreamingHandler) server.serve_forever()

 finally: camera.stop_recording()
recognizer = cv2.face.LBPHFaceRecognizer_create() recognizer.read('trainer/trainer.yml')
cascadePath = "Haarcascades/haarcascade_frontalface_default.xml" faceCascade = cv2.CascadeClassifier(cascadePath);
font = cv2.FONT_HERSHEY_SIMPLEX
#iniciate id counter
id = 0
# names related to ids: example ==> Marcelo: id=1, etc names = ['None', 'Marcelo', 'Harsh', 'Elon Musk', 'Z', 'W'] # Initialize and start realtime video capture
cam = cv2.VideoCapture(0)
cam.set(3, 640) # set video widht
cam.set(4, 480) # set video height
# Define min window size to be recognized as a face minW = 0.1*cam.get(3)
minH = 0.1*cam.get(4)
while True:
ret, img =cam.read()
img = cv2.flip(img, 0) # Flip vertically
gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
faces = faceCascade.detectMultiScale( gray,
scaleFactor = 1.2,
minNeighbors = 5,
minSize = (int(minW), int(minH)),
)
for(x,y,w,h) in faces:
cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)
id, confidence = recognizer.predict(gray[y:y+h,x:x+w])
# If confidence is less them 100 ==> "0" : perfect match if (confidence < 100):
id = names[id]
confidence = " {0}%".format(round(100 - confidence)) else:
id = "unknown"
confidence = " {0}%".format(round(100 - confidence)) print("unknown face")
whatsapp.whatsapp();
cam.release()
live()
cv2.putText(
img, str(id), (x+5,y-5,

font,
1, (255,255,255), 2
) cv2.putText(
img, str(confidence), (x+5,y+h-5), font,
1,
(255,255,0),
1
)
k = cv2.waitKey(10) & 0xff # Press 'ESC' for exiting video if k == 27:
break
# Do a bit of cleanup
print("\n [INFO] Exiting Program and cleanup stuff")
cv2.destroyAllWindows()

